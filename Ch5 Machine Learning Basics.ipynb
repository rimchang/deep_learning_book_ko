{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5, Machine Learning Basics\n",
    "\n",
    "## 5.1 Learning Algorithms\n",
    "\n",
    "- machine learning : A computer program is said to learn from experience E with respect to some class of tasks T\n",
    "and performance measure P , if its performance at tasks in T , as measured by P ,\n",
    "improves with experience E\n",
    "\n",
    "## 5.1.4 Example: Linear Regression\n",
    "\n",
    "\n",
    "$Let \\,\\,\\,\\, X^{(train)} = \\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\cdots  & x_{1n-1} & x_{1n}\\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " x_{m1}& x_{m2} & \\cdots & x_{mn-1} & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    " &  & \\mathbf{x_1}^T  &  & \\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " & & \\mathbf{x_m}^T & & \n",
    "\\end{bmatrix}$, $ \\,\\,\\,\\, \\mathbf{y^{(train)}} = \\begin{bmatrix}\n",
    " &  & y_1  &  & \\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " & & y_m & & \n",
    "\\end{bmatrix}$, $\\mathbf{w} = \\begin{bmatrix}\n",
    " &  & w_1  &  & \\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " & & w_n & & \n",
    "\\end{bmatrix}$\n",
    "\n",
    "즉 feature 갯수 n개, 데이터 갯수 m개!!\n",
    "\n",
    "(5.9) 까진 자명함으로 이후부터 유도합니다. 특히 (5.9) 에서 (5.10)으로 넘어갈때의 벡터미분이 어렵습니다.\n",
    "\n",
    "## $\\bigtriangledown_w(w^TX^{(train)T}X^{(train)}w - 2w^TX^{(train)T}y^{(train)} + y^{(train)T}y^{(train)}) = 0 \\,\\,\\,\\,\\,\\, (5.9)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2번째 term에 대한 유도   \n",
    "pf) $\\frac{\\partial }{\\partial w }w^TX^{(train)T}y^{(train)} = X^{(train)T}y^{(train)}$\n",
    "\n",
    "$w^TX^{(train)T}y^{(train)} =$ \n",
    "$\\begin{bmatrix}\n",
    "w_1 & w_2 & \\cdots & \\cdots & w_n\n",
    "\\end{bmatrix}\n",
    "$\n",
    "$\n",
    "\\begin{bmatrix}\n",
    " &  &  &  & \\\\ \n",
    " &  &   &  & \\\\ \n",
    " \\mathbf{x_1}& \\cdots & \\cdots & \\cdots & \\mathbf{x_m} \\\\ \n",
    " &  &  &  & \\\\ \n",
    " & &  & & \n",
    "\\end{bmatrix} \\\\\n",
    "$\n",
    "$\\begin{bmatrix}\n",
    "y_1\\\\ \n",
    "\\vdots\\\\ \n",
    "\\vdots\\\\ \n",
    "\\vdots\\\\ \n",
    "y_m\n",
    "\\end{bmatrix}$\n",
    "$= \\sum_{j=1}^nw_j\\sum_{i=1}^mx_{ji}y_i$\n",
    "\n",
    "\n",
    "$\\frac{\\partial }{\\partial w_1 }w^TX^{(train)T}y^{(train)} = \\frac{\\partial }{\\partial w_1 } \\sum_{j=1}^nw_j\\sum_{i=1}^mx_{ji}y_i = \\sum_{i=1}^mx_{1i}y_i=$$\\begin{bmatrix}\n",
    "x_{11} & x_{21} & \\cdots & \\cdots & x_{m1}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "y_1\\\\ \n",
    "\\vdots\\\\ \n",
    "\\vdots\\\\ \n",
    "\\vdots\\\\ \n",
    "y_m\n",
    "\\end{bmatrix}$\n",
    "${\\frac{\\partial }{\\partial w }w^TX^{(train)T}y^{(train)}}_{(i)}  = \\begin{bmatrix}\n",
    " &  & {\\frac{\\partial }{\\partial w_1 }w^TX^{(train)T}y^{(train)}}  &  & \\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " & & {\\frac{\\partial }{\\partial w_n }w^TX^{(train)T}y^{(train)}} & & \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    " &  & {\\mathbf{X^T}_{[1,:]}} \\mathbf{y}  &  & \\\\ \n",
    " &  & \\vdots  &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " &  & \\vdots &  & \\\\ \n",
    " & & {\\mathbf{X^T}_{[n,:]}} \\mathbf{y} & & \n",
    "\\end{bmatrix}=\\mathbf{X^T}\\mathbf{y}\n",
    "$\n",
    "\n",
    "where X^T[i,:] is ith row of X^T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1번째 term에 대한 유도  \n",
    "\n",
    "pf) $w^TX^{(train)T}X^{(train)}w = 2X^{(train)T}X^{(train)}w$\n",
    "\n",
    "$w^TX^{(train)T}X^{(train)}w = (w^T(X^{(train)T}X^{(train)}))w$ (선형사상은 결합법칙 성립)\n",
    "\n",
    "$(w^T(X^{(train)T}X^{(train)}))w$  \n",
    "$=(w^T(\\sum_{i=1}^mx_{ji}x_{ij}))w$ **(X^TX 를 summation으로 표현)**    \n",
    "$=(\\sum_{j=1}^n w_j(\\sum_{i=1}^mx_{ji}x_{ij}))w$ **(마찬가지로 앞의 w^T 를 summation으로 표현)**    \n",
    "$=\\sum_{j=1}^n(\\sum_{j=1}^n w_j(\\sum_{i=1}^mx_{ji}x_{ij}))w_j$   \n",
    "$=\\sum_{j=1}^n\\sum_{j=1}^n w_j^2(\\sum_{i=1}^mx_{ji}x_{ij})$  \n",
    "\n",
    "위의 수식의 의미는 즉 매트릭스는 결합법칙이 성립하고 summation 끼리도 결합법칙이 성립한다 는 것을 적용한것\n",
    "\n",
    "$\\frac{\\partial }{\\partial w} w^TX^{(train)T}X^{(train)}w$  \n",
    "$ = \\frac{\\partial }{\\partial w}\\sum_{j=1}^n\\sum_{j=1}^n w_j^2(\\sum_{i=1}^mx_{ji}x_{ij})$  \n",
    "$= \\sum_{j=1}^n\\sum_{j=1}^n 2w_j(\\sum_{i=1}^mx_{ji}x_{ij})$  \n",
    "$=2\\sum_{j=1}^n(\\sum_{j=1}^n(\\sum_{i=1}^mx_{ji}x_{ij}))w_j$  **(summation을 매트릭스로 표현)**    \n",
    "$=2\\sum_{j=1}^n(X^{(train)T}X^{(train)})w_j$  \n",
    "$=2X^{(train)T}X^{(train)}\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터, 혹은 매트릭스에 대한 미분은 수식을 elementwise하게 나타내고, 이를 미분한뒤 다시 vector, matrix form으로 나타내 주면 된다!!\n",
    "\n",
    "## $=>\\,\\,2X^{(train)T}X^{(train)}w-2X^{(train)T}\\mathbf{y^{(train)}} =0 \\,\\,\\,\\, (5.11)$  \n",
    "## $=> w = (X^{(train)T}X^{(train)})^{-1}X^{(train)T}\\mathbf{y^{(train)}} \\,\\,\\,\\, (5.12)$\n",
    "\n",
    "## 5.2 Capacity, Overfitting and Underfitting\n",
    "\n",
    "머신러닝에서의 어려운 점은 새로운 인풋에 대해서도 잘 작동해야 한다는 것입니다. 이러한 관찰되지 않은 입력에서 잘 작동할 수 있는 능력을 <b>generalization</b> 이라고 합니다.\n",
    "\n",
    "전형적으로 머신러닝 모델을 학습할때 우리는 트레이닝 데이터에서만 error measure를 계산하고 이를 <b>tranining error</b> 라고 부릅니다. 학습 동안 이 tranining error를 줄이는 방향으로 학습됩니다. 이는 traniniing data에서의 training error를 줄이는 간단한 opimization problem으로 볼 수있습니다. 하지만 머신러닝과 optimization과의 다른 점은 generaliation error가 낮아지는 것을 원하는 점이 다릅니다. <b>generalization error는 새로운 입력에 대한 error의 기댓값으로 정의됩니다</b> 이 기댓값은 시스템이 실제로 마주치게 될 것이라고 생각되는 data distribution에서 얻어진 서로 다른 input에 대해 계산됩니다.\n",
    "\n",
    "linear regression 예제에서 tranining error를 최소화 하도록 모델을 학습했습니다. 그러나 우리가 원하는 것은 test error가 낮아지도록 하는 것입니다. traning data만을 학습하는 것이 test set에서의 성능에 어떤 영향을 끼치게 될까요? <b>statistical learning theory</b> 에서는 몇가지 답을 제공합니다. training, test data set이 아무렇게나 수집된 것이라면, 우리가 할수 있는 것이 별로 없습니다. training, test dataset이 어떻게 수집도었는지에 대한 몇가지 가정을 통해 이론을 전개 할 수 있습니다.\n",
    "\n",
    "1. train, test dataset이 <b>data generating distribution</b> $p_{model}$을 따른다고 가정하며 생성되는 과정을 <b>data generating process</b> 라고 합니다. \n",
    "2. 각각의 데이터 포인트들은 iid 라고 가정하며 이는 독립(<b>independent</b>)이며 같은 분포(<b>identically distributed</b>)에서 생성된다고 가정합니다.\n",
    "\n",
    "iid라는 가정을 통해 tranin ,test error와의 관계를 수학적으로 연구 할 수 있습니다.\n",
    "\n",
    "위와 같은 가정을 통해 얻을 수 있는 것중 하나는 train error, test error의 기댓값이 같을 것이라는 것입니다. $p(x,y)$를 알고 있다고 가정하면 샘플링을 반복하여 train, test set을 만들 수 있습니다. 어떤 고정된 $w$(weight) 를 생각하면, 같은 웨이트와, data sampling을 따르므로 train, test set에 대한 기대값이 같아지게 됩니다.\n",
    "\n",
    "물론 우리가 머신러닝 알고리즘을 사용할때 파라미터를 고정하지 않습니다. training set에서 데이터를 샘플링하고 이를 사용하여 training set error를 줄이도록 파라미터를 선택합니다. 그 후 test set 에서 데이터를 샘플링합니다. 이러한 프로세스에서 test error에 대한 기댓값은 train error에 대한 기댓값보다 같거나 크게 됩니다. 머신러닝 알고리즘이 잘 작동하도록 요인은 다음과 같습니다.\n",
    "\n",
    "1. traning error를 작게 만드는것\n",
    "2. training error와 test error의 차이를 줄이는 것\n",
    "\n",
    "\n",
    "underfitting : 모델이 train error를 충분히 낮아지게 하지 못하는 것  \n",
    "overfitting: train error와 test errror의 차이가 큰 것\n",
    "\n",
    "이러한 overfitting, underfitting은 <b>capacity</b> 와 관련되어져 있으며 capacity가 낮다면 train error를 줄이기 힘들어할 것이며, capacity가 높다면 overfitting을 보이는 경향이 있습니다.\n",
    "\n",
    "<b>hypothesis space</b> : learning 알고리즘의 솔루션으로 가능한 function의 집합, 이를 조절함으로써 모델의 capacity를 조절가능하다.\n",
    "\n",
    "머신러닝 알고리즘은 일반적으로 task complexity, traning data의 양에 알맞는 capacity를 가질때 좋은 성능을 보이며 capacity 를 조절하기 위해서는 feature의 갯수를 늘리거나, feature와 관련된 새로운 파라미터 (x^2와 같은)를 추가함으로써 조절할 수 있다.\n",
    "\n",
    "<b>representational capacity</b> : model은 단지 traning loss를 줄이기 위해 파라미터를 변경함으로써 얻을 수 있는 family of function(이것도 hypothesis space아닌가) 를 명시해 줍니다. 이러한 family of function을 representational capacity라고 합니다.\n",
    "\n",
    "<b>effective capacity </b> : capacity는 model를 선택하는 것에만 의존하지 않습니다. hypothesis space상에서 가장 좋은 fucntion을 찾는 것은 매우 어려운 최적화 문제이고, 실제로는 best function을 찾진 못하며 train error를 많이 줄이는 some function을 찾게 됩니다. 이는 최적화가 완벽하지 않기 때문에 얻게 되는 추가적인 문제입니다. 즉 optimization + hypothesis space를 모두 고려한 capacity가 effective capacity이며 이는 representational capacity보다 낮습니다.\n",
    "\n",
    "<b>Occal's razor</b> : 비슷한 아웃풋을 내는 hypothese들이 존재한다면 가장 간단한 model을 선택하라는 원리를 말합니다. 이러한 아이디어는 20세기에 statistical learning theory연구자들에 의해 공식화 되었고 더 정교해졌습니다.\n",
    "\n",
    "<b>VC dimension</b> : statistical learning theory은 model capcity에 대한 다양한 의미를 제공합니다. 가장 잘 알려진 것은 VC dimension 이며, 이는 binary classfier의 capacity를 측정합니다. 이는 classfier가 완벽하게 분류할 수 있는 최대의 train example의 갯수로 정의됩니다. \n",
    "\n",
    "<b>하여튼 가장 중요한 것은 위에서 언급한것들로 generalization error의 상한을 구할 수 있으며 capacity가 높아지면 gap이 커지고, train example이 많아지면 gap이 작아집니다. 또한 머신러닝 알고리즘이 작동하는 것은 이러한 상한을 더 타이트하게 만들도록 학습되어 결국에는 generalization error가 줄어들게 되기 때문에 작동한다는 것입니다.</b>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 높은 capacity를 달성하기 위한 가장 극단적인 케이스로 <b>non-parametric</b> 모델을 소개합니다. 파라미터 벡터의 사이즈가 유한한 parametirc model과 다르게 non-parametric 모델은 이러한 제한이 없습니다.\n",
    "\n",
    "때때로 nonparametric 모델은 이론적이며 실제로 구현 불가능 한 경우가 있습니다.(모든 가능한  확률분포를 탐색해야 하는 알고리즘은 구현이 불가능합니다.) \n",
    "\n",
    "실제로 구현 가능한 하나의 예는 <b>nearest neighbor regression</b> 으로써 test point와 가장 가까운 traning point의 아웃풋을 통해 예측합니다. 이 알고리즘은 L2 norm과 같은 distance metric을 일반화한 형태의 learned distance metrics 알고리즘으로 일반화 될 수 있습니다. 만약 알고리즘이 nearest point 의 y_i를 평균을 하는 것이 가능하다면, 이 알고리즘은 어떠한 데이터에서도 minium possible training error를 달성할 수 있습니다.\n",
    "\n",
    "마지막으로, parametric learning 이 필요한 파라미터의 수를 늘릴 수 있는 다른 nonparameric learning 알고리즘을 만듬으로써 nonparametric 모델을 구현 가능합니다. 예를들어 linear regression이 학습할 polynomial degrre를 바꾸는 outer loop learning알고리즘을 생각 해 볼 수 있습니다.\n",
    "\n",
    "가장 이상적인 형태는 일종의 oracle(모든것을 다 알 수있는 경우) 로써 data generating distribution을 모델로 삼는것입니다. data generating distribution을 모델로 쓴다고 해도 엘러를 0을 달성하지는 못할 것이며 이는 distribution에 노이즈가 여전히 있기 떄문입니다. supervised learing의 경우에 x->y로의 매핑은 근본적으로 랜덤합니다, 혹은 y가 x뿐만 아닌 다른 변수들을 포함한 것에 대한 deterministic function일 수 있습니다. <b>이러한 true distribution p(x,y) 을 안다고 가정했을지라도 얻어진 에러를 Bayes error 라고 합니다.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 The No Free Lunch Theorem\n",
    "\n",
    "learning theory는 유한한 트레이닝 데이터에서도 머신러닝 알고리즘이 일반화를 잘 할 수 있다고 주장합니다. 이는 몇가지 논리적 원리와 모순을 보입니다. 제한된 example로 부터의 귀납적 추론, 일반적인 규칙을 추론하는 것은 논리적으로 불가능합니다. 논리적으로 어떠한 규칙을 추론하기 위해서는 세상에 존재하는 모든 데이터에 대한 정보가 있어야 합니다.\n",
    "\n",
    "머신러닝에서는 이러한 문제를 확률 규칙으로 회피합니다. <b> 머신러닝은 전체의 집합이 아닌 most member set에서의 probably correct rule을 찾도록 해줍니다.</b>\n",
    "\n",
    "불행하게도, 이러한 것은 전체의 문제를 해결해 주지 않습니다. 머신러닝에서의 <b>no free lunch theorem</b> 은 모든 가능한 data-generating distribution이 평균적으로 나타난다고 가정한 classficatoin 알고리즘은 같은 error를 보인다는 것입니다. 이 의미는 어떠한 머신러닝 알고리즘도 절대적으로 다른 알고리즘 보다 좋다고 하지 못한다는 뜻입니다. \n",
    "\n",
    "하지만 다행히도 data-generating distribution을 실제 세계의 application이 잘 따르는 distribution으로 가정한다면 우리는 이 특정 distribution에서 더 잘 작동하는 알고리즘을 디자인 가능합니다. 머신 러닝 연구는 즉 우리의 AI가 맞닥들일 distribution에서 더 잘 작동하는 머신러닝 알고리즘을 연구하는 것입니다.\n",
    "\n",
    "## 5.3 Hyperparameters and Validation Sets\n",
    "\n",
    "<b>Hyperparameter </b> : learning 알고리즘이 데이터로 부터 배울수 없는 파라미터 (최적화하기 힘들거나 불가능한 파라미터)\n",
    "\n",
    "## 5.4.1 Point Estimation(점 추정)\n",
    "\n",
    "Point estimation은 알고 싶은 어떠한 것에 대한 single \"best\" prediction을 제공하려고 합니다. 일반적으로 우리가 알고 싶어하는 것은 하나의 파라미터 나 vector of parameter가 될 수 있으며 linear regression에서의 weight들로 볼 수 있습니다. 또한 function 전체에 대해도 가능합니다.\n",
    "\n",
    "추정된 파라미터와 그들의 true value를 구별하기 위해 추정도니 파라미터를 $\\hat{\\theta}$ 로 나타냅니다.\n",
    "\n",
    "데이터가 iid 분포에서 뽑혔다고 가정할때 <b>poinrt estimator or statistic</b> 은 데이터에 대한 어떠한 함수가 될 수 있습니다.\n",
    "\n",
    "## $\\hat{\\theta_m} = g(x^{(1)},\\cdots,x^{(m)}) \\,\\,\\,\\, (5.19)$\n",
    "\n",
    "위와 같은 정의는 g라는 함수가 true theta와 가까워질 필요가 없습니다. 또한 g의 치역이 theta와 같을 필요도 없습니다. 이러한 point estimator의 정의는 매우 일반적으로 정외된 것이며 매우 유연한 estimator를 설계할 수 있도록 합니다. 거의모든 함수는 estimator를 통해 양적으로 표현될 수 있으며 <b> 좋은 estimator란 true $\\theta$와 가까운 값을 출력하는 estimator가 됩니다</b>\n",
    "\n",
    "이제 통계학자들의 관점, 특히 빈도주의의 관점에서 살펴보면 우리는 true paramete $\\theta$를 고정되고 모르는 값으로 가정하였고 $\\hat{\\theta}$를 데이터에 대한 어떤 함수로 가정했습니다. data는 data-generating distribution에 의한 random process로 부터 생성되기 때문에 데이터에 대한 어떠한 함수 역시 random 입니다. 즉 $\\hat{\\theta}$는 random variable이 되게 됩니다.\n",
    "\n",
    "point estimation은 input, target 변수간의 관계를 설명할 수 있습니다. 이러한 경우의 point estimate를 function estimation이라고 합니다.\n",
    "\n",
    "## Function estimation\n",
    "\n",
    "어떤 경우 우리는 function에 대한 estimation에 관심을 가질 수 있습니다. 이런 경우 우리는 input vector x가 주어졌을때의 변수 y를 예측하려고 합니다. 여기서 y,x의 관계를 근사하는 어떤 함수 f(x)가 있다고 가정합시다. 예를들어 y=f(x)+e 로 가정하며 e는 f(x)가 설명하지 못하는 부분을 나타냅니다. function estimation에서는 f에 대한 근사 혹은 f^에 관심을 가지게 됩니다. function estimation 또한 파라미터를 추정하는 것과 똑같습니다. function estimator는 간단히 말해서 function space에서의 point estimator입니다. linear regreesion의 경우에 plynomial regression 예제는 파라미터 w를 추정하는 경우와 function $\\hat{f}$를 추정하는 경우 둘다로 해석될 수 있습니다.\n",
    "\n",
    "## 5.5 Maximum Likelihood Estimation\n",
    "\n",
    "우리는 몇가지 estimator에 대해 살펴보고 그들의 특징에 대해 분석했습니다. 그렇다면 이러한 estimator들이 어디에서 유도된 것일까요 모든 함수에 대해 이들이 좋은 estimator인지 확인하기 위해 bias, variance를 계산해 보는 것 대신 우리는 각기 다른 모델로 부터 좋은 estimator를 유도해 내는 방법이 있습니다.\n",
    "\n",
    "가장 보통의 원리중 하나가 maximum likelihood princeiple입니다.\n",
    "\n",
    "m개의 샘플 X={x_1, x_2,,,,x_m} 이 존재하고 data-generating distribution p_data(x) 를 모른다고 가정해봅시다.\n",
    "\n",
    "$p_{model}(x;\\theta)$ 를 일종의 p_data에 대한 parametric estimator라고 가정해봅시다. \n",
    "\n",
    "5.56 -> 5.56 으로 갈 수 있는 이유는.. iid 이기 떄문이다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5.57) 에서의 prodcut 는 여러가지로 불편합니다. 예를들어 이는 numerical underflow가 발생하기 쉽습니다. 더 다루기 쉬운 수식으로 바꾸면서 같은 최적화 문제를 풀기 위해서 log를 도입하며 이는 argmax를 바꾸지 않지만 product를 sum으로 바꿔줍니다.\n",
    "\n",
    "argmax는 1/m을 곱해줘도 바뀌지 않기 때문에 (5.58)에 1/m을 곱해줌으로써 (5.59)와 같은 expectation term으로 나타냅니다. 이렇게 <b>1/m으로 곱해준 criterion은 train data에 의해 정의된 empirical distribution에 대한 expectation이 됩니다.</b>\n",
    "\n",
    "1. minimize KL divergence == minimize crossentropy == maximize likelihood == minimize negative likelihod\n",
    "2. KL divergence로 보는 관점이 도움이 될 때가 있는데.. minimum value가 0이된다. 즉 loss를 비교하기가 쉽다.\n",
    "\n",
    "많은 사람들이 cross entropy가 베르누이 혹은 softmax distribution의 NLL 의 꼴이라고 오해하고 있다. <b>NLL을 사용하는 모든 loss는 cross-entropy이며 이는 p_model, p_data 의 분포의 차이를 나타낸다. 특히 MSE는 empirical distribution과 Gaussian model의 cross-entropy가 된다.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.1 Conditional Log-Likelihood and Mean Squared Error\n",
    "\n",
    "<b>Example: Linear Regression as Maximum Likelihood</b> 이 예제에서 linear regression을 일종의 maximum likelihood estimation으로 바라보는 관점을 살펴볼 것입니다.  하나의 $\\hat y$을 예측하는 것 대신 이제 조건부 확률분포 $p(y|x)$ 를 모델링 한다고 생각해 봅시다. 무한한 매우 많은 train set이 있다고 상상하면 우리는 같은 인풋 x를 같지만 다른 y를 가지는 점들을 찾을 수 있습니다. learning 알고리즘의 목적은 이러한 상황에 맞는 $p(y|x)$을 찾는 것입니다. 이전에 살펴봤던 linear regression과 같은 결과를 얻기 위해서 $p(y|x)=N(y;\\hat y (x;w) ,\\sigma^2)$ 로 가정합시다. $\\hat y (x;w)$ 은 gaussian의 mean이 무엇인지를 예측하도록 합니다. 이 예제에서는 분산은 고정되어져 있다고 생각합니다. 즉 분산이 고정되어져 있을때의 gaussian mean을 예측하는 모델을 설계한 것입니다. 위와 같은 $p(y|x)$ 에 대한 가정이 이전에 봤었던 linear regression과 같은 수식으로 유도되는 것을 살펴볼 것입니다. train example이 iid라고 가정하면 조건부 log-likelihood는 다음과 같이 주어집니다.\n",
    "\n",
    "## $\\sum_{i=1}^m log p(y^{(i)}| \\mathbf{x}^{(i)}; \\mathbf{\\theta})) \\,\\,\\,\\, (5.64)$\n",
    "\n",
    "그냥 쭉쭉 풀어서 유도해보면 (5.65) 가 나오며 1/m 앞에 곱해줘도 argmax는 안변하고.. constant 뺴줘도 안변하니 (5.66)이 나온다.\n",
    "\n",
    "MSE와 maximum likelihood는 서로 다른 값을 가지지만 optimum 은 같아지게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.2 Properties of Maximum Likelihood\n",
    "\n",
    "maximum likelihood의 가장 주요한 점은 <b>asymptotically best estimator</b>라는 것입니다. 즉 train example의 갯수 m이 증가할 수록 수렴 속도가 빨라지게 됩니다.\n",
    "\n",
    "몇가지 조건하에서 maximum likelihood estimator는 consistency 한 특징(데이터가 많을 수록 true distribution으로 수렴한다.)을 가지게 됩니다. 이 의미는 train example의 갯수 $m -> \\infty$ 이면 추정된 파라미터가 true 파라미터로 수렴한다는 것입니다. 그 조건은 다음과 같습니다.\n",
    "\n",
    "1. true distribution이 family of p_model 이여야 한다. 이렇지 않으면 어떤 estimator도 p_data를 recover할수 없다.\n",
    "2. p_data가 \\theta에 대한 일대일 함수여야 한다. 그렇지 않으면 p_data 를 구할 순 있지만 어떤 \\theta를 사용해야 할지 결정할 수 없다.\n",
    "\n",
    "efficeincy estimator : 어떠한 consistent estimator도 maximum likelihood estimator보다 MSE가 낮을 수 없다.\n",
    "\n",
    "### maximum likelihood props 정리\n",
    "\n",
    "1. consistency estimator (조건 1, p_data is family of p_model, 조건 2, p_data is one-to-one function w.r.t theta)\n",
    "2. best efficeincy estimator (MSE의 경우 증명을 소개, 즉 p_model이 가우시안일때의 best efficeincy estimator)\n",
    "\n",
    "## 5.7.2 Support Vector Machines\n",
    "\n",
    "커널 베이스 함수는 $\\phi(x)$ 를 통해 모든 인풋을 pre-processing 하고 새로운 transformed space에서 linear model을 학습 하는 것과 동일하다.\n",
    "\n",
    "커널 트릭이 효과적인 두가지 이유가 있다. \n",
    "\n",
    "1. non-linear 커널을 사용함으로써 convex optimization을 가능하게 하며 이는 효율적인 수렴을 보장한다. 이것이 가능한 이유는 $\\phi$를 고정하고 optimization은 오직 $\\alpha$ 에만 적용되기 때문이며 이는 transfromed 공간에서의 linear 한 함수에 대한 optimization으로 문제를 풀 수 있게 한다.\n",
    "\n",
    "2. kernel function 을 도입하게 되면 원래 두개의 벡터 x,y에 $\\phi$를 적용하고 내적을 하는 것보다 효율적으로 구현할수 있으며며 이를 통해 연산량을 매우 줄일 수 있게된다.\n",
    "\n",
    "어떤 경우에는 $\\phi(x)$ 가 무한한 차원을 가질때가 있으며 이를 naive하게 구현하기 위해서는 무한한 연산량이 필요해 연산 자체가 불가능하다. 하지만 커널 트릭을 사용하면 매우 효율적으로 가능하게 된다. 많은 경우에 $k(x,x')$ 는 non-linear이며 x에대한 tractable function이 된다. 심지어 커널에 대응하는 $\\phi(x)$ 가 intractable이더라도 커널은 tractable 해질 수가 있다. \n",
    "\n",
    "이에 대한 예제로 tractable kernel을 가지는 infinite-dim feature space의 경우가 있다. 어떠한 feature mapping $\\phi(x)$ 를 모든 non-negative int x 에 대해 정의하고 싶다고 해보자. $\\phi(i)$ 이러한 사상이 i번째만 i이고 나머지는 모두 zero인 사상이라고 해보자.(즉 integer를 받아서 벡터로 만들어주는 사상) 이때 커널을 $k(x,x^{(i)}) = min(x,x^{(i)})$ 과 같이 정의할 수 잇으며 이는 infinite-dimensional dot product와 동치이다.\n",
    "\n",
    "가장 많이 쓰이는 커널중 하나는 Gaussian kernel이다.\n",
    "\n",
    "## $k(u,v) = N(u-v; 0, \\sigma^2 I)$\n",
    "\n",
    "이 커널은 <b>radial basis function</b> 으로 알려져 있으며 함수의 모양이 방사형여서 이런 모양이 붙었다고 한다. 이 가우시안 커널은 infinite-dimensional space에서의 dot product와 일치합니다.\n",
    "\n",
    "이러한 가우시안 커널을 일종의 <b>template matching</b> 으로 생각할 수 있습니다. train data (x,y) 은 클래스 y에 대한 일종의 template가 되며 새로운 test point x' 가 x의 근처에 있다면 가우시안 커널이 매우 높은 response를 보이게 됩니다. 이 의미는 x'와 x라는 template와 매우 비슷하다는 것입니다. 그후 모델은 x'를 위해 x와 관련된 y 클래스에 더 높은 가중치를 두게 됩니다. \n",
    "\n",
    "svm은 이러한 커널트릭을 통해 성능 향상을 얻을 수 있습니다. 다른 linear model들도 이러한 방법을 통해 성능을 향상시킵니다. 커널 트릭을 활용하는 이러한 카테고리의 알고리즘들을 kernel method or kernel machine이라고 부릅니다.\n",
    "\n",
    "kernel machine의 가장 큰 단점중 하나는 decision function을 구성하기 위해 필요한 cost가 train example의 수에 linear하다는 것이다. 이는 i번째 train example이 a_i를 위해 필요하기 때문입니다. svm은 이를 해결하기 위해 a vector가 대부분 zero이도록 만듭니다. 이 경우 새로운 sample에 대한 예측을 위해 non-zero a_i만을 사용하여 계산할 수 있게 만듭니다. 이러한 non-zero a_i들을 <b>support vector</b> 라고 부릅니다.\n",
    "\n",
    "[커널 설명](https://nzer0.github.io/reproducing-kernel-hilbert-space.html)\n",
    "\n",
    "## 5.7.3 Other Simple Supervised Learning Algorithms\n",
    "\n",
    "one-hot vector에 대한 avreage는 일종의 확률분포로 볼 수 있습니다. knn은 근처의 k point들의 y를 average하며 이또한 일종의 확률분포로 생각 할 수 있습니다. knn은 매우 높은 capacity를 가질 수 있습니다. 예를들어 0-1 loss (맞으면 0 틀리면 1)을 가지는 multiclass classfication을 생각해 봅시다. 이러한 경우 k=1 인 knn은 train sample이 무한으로 감에 따라 bayes error의 두배에 수렴합니다. k=1인 경우에서 bayes error와의 차이 나는 부분은 같은 distance를 가지는 point중 에서 random 하게 이웃을 선택하는 것 때문에 발생합니다. 무한한 데이터가 존재할 때 모든 test point x'는 거리가 0인 무한한 많은 train set에서의 point를 가질 것입니다. 거리가 0인 point들 중에서 랜덤하게 하나의 이웃을 선택하는게 아닌 vote(즉 average)를 할 수 있게 한다면 이는 bayes error로 수렴합니다. \n",
    "\n",
    " knn의 high capacity는 매우큰 train set일때의 높은 성능을 허락하지만 매우 연산량이 높습니다. 또한 유한한, 작은 train set에서는 성능이 좋지 않습니다. knn의 또다른 단점중 하나는 어떤 feature가 더 좋은지에 대한 것을 배울 수 없습니다. 만약 100개의 피쳐중 하나의 피쳐만 의미가 있는 데이터 셋에서 knn을 수행한다면 매우 안좋은 결과를 보일 것입니다. \n",
    " \n",
    " ## 5.8 Unsupervised Learning Algorithms\n",
    " \n",
    " unsupervised learning task에 대한 전통적인 정의는 best representation of data를 찾는 것입니다. 세가지 정도의 많이 사용되는 것이 있습니다.\n",
    " \n",
    " 1. low dimensional representation : 데이터를 더 낮은 representation space를 갖는 곳에서 representation\n",
    " 2. sparse representation : 대부분이 zero인 vector로 representation. 이들은 보통 차원을 늘리는 것을 피룡로 하기 때문에 대부분이 zero여도 정보를 그닥 많이 잃지 않습니다. sparse representation의 결과의 point들은 representation space의 축에 분포하는 경향이 있습니다.\n",
    " 3. independent representation : underlying data distribution의 variantion을 disentangle하여 representation dimension이 독립이도록 만듬\n",
    " \n",
    " ## 5.8.2 k-means Clustering\n",
    " \n",
    " k-means는 모든 train data를 k size cluster로 나눕니다. <b>이는 모든 input x를 one-hot code vector h 로 나타내는 알고리즘이라고 생각 할 수 있습니다.</b> (bag of word를 생각해보자.!! 이는 이미지 patch에 대한 one-hot representation 이 된다) 또한 이는 sparse representation의 예로 볼 수있다.\n",
    " \n",
    " one-hot code는 몇가지 통계적 이점을 가지고 있으며 (이는 본질적으로 같은 클러스터에 있는 example들은 서로 비슷하다는 생각에서 나왔다) 하나의 integer 로 표현될 수 있어 연산량의 이점이 있다.\n",
    " \n",
    " one-hot code의 문제점중 하나는 clustering 안에 속하는 example들은 비슷하다는것을 알지만 서로 다른 클러스터간의 거리를 모두 같다고 본다. 예를 들어 red car, red truck, gray truck의 세개의 클러스터가 있다면 red car, red truck이 더 비슷한데 모두의 거리는 1이 된다. 이 때문에 우리는 distributed reprsentation을 더 선호한다.\n",
    " \n",
    " ## 5.9 Stochastic Gradient Descent\n",
    " \n",
    " 과거에는 non-convex optimization problem이 아닌 문제에 gradient descent 알고리즘을 적용하는 것은 바보같은 짓이라고 생각했습니다. 하지만 현재에는 파트2 에서 기술될 알고리즘들과 딥러닝 알고리즘에도 잘 되는 것을 보였습니다. non-convex 에서의 gradient descent는 local minimum에 수렴한다는 보장은 없지만 비교적 low cost에 빠르게 수렴하기 때문에 유용합니다.\n",
    " \n",
    " fixed model size에서 SGD update당 cost는 train set size m에 의존하지 않습니다. train data가 커질수록 더 큰 모델을 사용하곤 하지만 SGD는 그러지 않아도 되며 train data가 커지면 iteration 수를 늘리면 됩니다. 그러나 만약 train data size m이 무한대로 커지게 되면, 무한한 모든 train set example을 다 학습하기 전에 best possible test error로 수렴하게 될 것입니다. 즉 데이터 수를 늘리는 것이 best possible test error를 달성하기 위한 시간을 늘리는 것은 아니라는 의미입니다. 이런 관점에서 SGD를 통해 모델을 학습하는 것에 대한 asymptotic cost 는 m에 대해 O(1)이 되게 됩니다. \n",
    " \n",
    " ### 정리하자면 SGD는 데이터 셋에 대한 constant cost를 가지고 있어 매우 큰 데이터에 효율적이다.\n",
    " (매우 큰 데이터셋의 경우 linear or svm의 경우도 closed form이 아닌 sgd를 통해 학습시키기도 한다고 한다)\n",
    " \n",
    " non-linear learning 알고리즘을 위한 것중 하나가 kernel machine인데.. 이는 O(m^2) 이다.. 딥러닝이 주목받게 된 것중 하나가 매우 큰 데이터에 대해서 효율적으로 non-linear model을 학습할 수 있기 때문이다.\n",
    " \n",
    " ## 5.11.1 The Curse of Dimensionality\n",
    " \n",
    " 많은 머신러닝 문제들은 데이터의 차원이 높을때 문제를 겪고 있습니다. 이 현상은 차원의 저주로 알려져 있습니다. 특히 안좋은 영향을 끼치는 부분은 변수의갯수가 증가함에 따라 구별해야 하는 가능성의 수가 지수적으로 증가한다는 것입니다. 차원의 저주는 컴퓨터사이언스와 특히 머신러닝에서 많은 영향을 끼칩니다. \n",
    " \n",
    " <img src='https://bigsnarf.files.wordpress.com/2013/06/screen-shot-2013-06-14-at-11-16-30-am.png' width='420' height='320' />\n",
    " \n",
    "차원의 저주로 인해 겪게되는 하나의 문제점 중 하나는 statistical challenge 입니다. 위의 그림에서도 볼 수 잇듯이 statistical challenge가 발생하는데 이는 train example의 갯수보다 x의 가능한 조합(5grid의 1차원 데이터의 가능한 x의 조합은 5개이지만 5grid의 2차원 데이터의 가능한 조합은 5^2=25 가 된다.) 들이 더 많을 떄 발생합니다. 이러한 문제를 이해하기 위해 input space를 일종의 grid로 나눠서 생각해 봅시다. 낮은 차원일때는 대부분의 grid가 데이터로 채워진 것을 볼 수 있습니다. 새로운 데이터에 대해서 일반화를 할때는 가장 간단히 할 수 있는 방법은 같은 grid 안에 존재하는 train example을 가지고 예측을 수행하면 됩니다. 예를 들어 x 라는 point에서의 확률분포를 추정하기 위해서는 가장 간단한 경우는 같은 grid 안에 있는 인풋들의 평균 갯수들을 출력하면 됩니다. (즉 [1,3,8,2,1]/15 과 같은 count들이 확률분포를 나타내게 된다.)  classfy를 하고 싶다면 같은 grid안의 인풋들 중에서 가장 많이 나온 class로 예측 하면 됩니다. regression을 하고 싶다면 grid 안의 인풋들의 y값을 평균내면 됩니다. 하지만 어떤 grid안에 train data point가 없다면 어떻게 될까요? high dimension space의 가능한 조합이 매우 크기 때문에 대부분의 grid 에는 관련된 train data point가 존재하지 않게 됩니다. 그렇다면 이러한 경우 어떠한 예측을 하게 될까요? 많은 전통적인 머신러닝 알고리즘들은 새로운 point가 근처의 train point의 output과 근사적으로 같다고 가정합니다. 결국 차원의 저주에 고통을 받게 됩니다.\n",
    "\n",
    "## 5.11.2 Local Constancy and Smoothness Regularization\n",
    "\n",
    "머신러닝에서 많이 사용되는 implicit prior는 <b> smoothness prior, local constancy prior</b> 가 있습니다. 이러한 prior는 우리가 배워야할 함수가 작은 region안에서는 많이 변하지 않는다는 것입니다.\n",
    "\n",
    "많은 간단한 알고리즘들은 이러한 prior에만 전적으로 의존하며 AI level-task와 같은 복잡한 문제에서는 안좋은 결과를 보입니다. 이 책에서는 딥러닝이 어떻게 implicit or explicit prior를 통해 일반화 오류를 줄이는지 보일 것이며 smoothness prior 만으론 왜 불충분 한지를 보여줄 것입니다.\n",
    "\n",
    "학습될 함수가 smooth or locally constant 해야 한다는 것에 대한 implicit or explicit prior를 추가하는 방법은 여러가지가 있습니다. 이러한 방법들은 모두 f\\* 라는 함수를 배우기 위해 밑의 조건을 만족하도록 하는 과정에서 유도 됩니다.\n",
    "\n",
    "### $f*(x) \\approx f*(x + \\epsilon) \\,\\,\\,\\, (5.103)$\n",
    "\n",
    "이는 대부분의 configurationx, small change 에 대해서 만족되어야 합니다. 이 의미는 <b>인풋 x에 대한 좋은 예측을 얻고 싶다면 x 근처의 point들도 좋은 예측을 해야 한다는 것입니다.</b> 만약 이웃한 point에서 좋은 예측을 얻었다면 그것들을 결합하여(평균 혹은 보간법을 통해) 이웃한 point들도 가능한한 동의할만한 예측을 해야 합니다.\n",
    "\n",
    "local constancy의 가장 극단적인 예는 knn 종류의 학습 알고리즘입니다. k=1 인경우 region의 갯수가 train example의 갯수를 넘지 않습니다. k=2 인 경우에는.. region의 갯수가 오히려 더 적어지겠지..아닌가??\n",
    "\n",
    "knn 알고리즘이 단지 근처의 train example의 output을 복사 하는 것에 비해서 대부분의 kernal machine 알고리즘은 근처의 train example의 output을 통해 interpolation을 수행합니다. 중요한 커널의 종류중 하나는 <b>local kernel</b> 이며 이는 u=v 일때 크며 u,v가 멀어질수록 낮은 값을 가지게 됩니다. local kernel은 template matching을 수행하는 일종의 유사도를 측정하는 함수로 볼 수 있으며 test example x가 다른 train example과 얼마나 비슷한지를 measure 합니다. \n",
    "\n",
    "    - knn은 k값에 따라 local constancy가 결정되며 (k가 클수록 smooth한 region, 즉 local constancy가 커진다) svm은 내적(유사도)에 따라 interpolation을 수행함으로써 local constancy를 조절한다.\n",
    "\n",
    "decision tree의 경우도 input space를 가능한 만큼 많이 쪼개기 때문에 smoothness-based learning에 대한 한계점을 느끼고 있습니다. decision tree의 경우는 input space를 그들의 leaf 만큼의 region으로 쪼개며 각 region마다 separate parameter를 가지게 됩니다. 만약 target function이 n개의 leaf를 가지는 tree를 필요로 한다면 tree를 학습시키기 위해서는 적어도 n개의 train example이 필요합니다. 혹은 일정한 수준의 statistical confidence를 달성하기 위해서는 n의 배수의 train example이 필요합니다.\n",
    "\n",
    "일반적으론 O(k) region을 구별하기 위해선 모든 방법론은 O(k) example을 필요로 하며 전형적으론 O(k) 파라미터가 존재하며 region에 대해서는 O(1)을 가지는 파라미터 입니다. knn의 경우엔 각각의 train example이 하나의 region을 설명하기 위해 필요합니다.\n",
    "\n",
    "train example보다 많은 region을 가지도록 하는 방법이 무엇일까요? 오직 smoothness만을 가정하는 것은 더 많은 region을 가지도록 하지 못합니다. 예를 들어 target function이 일종의 체스판이라고 상상해 봅시다. 체스판에는 많은 변형들이 포함되어져 있지만 이를 만들기 위한 간단한 구조가 있습니다. train example의 갯수가 세프나의 칸보다 매우 작다고 상상해 봅시다. local generalization, smoothness, local constancy prior 에 기반하면 우리는 같은 사각형 안에 놓여있는 train example과 같은 색깔을 가진다고 추측할 수 있습니다. learner가 train example을 포함하고 있지 않은 사각형에 대해서도 체스판과 같은 패턴으로 올바르게 학습했을 것이라는 보증이 없습니다. 이러한 prior 하나만으로는 같은 사각형안에 있는 point의 색깔만을 알려주지 않으며 체스판의 모든 색을 제대로 알기 위해서는 region마다 하나의 train example이 필요합니다.\n",
    "\n",
    "smoothness assumption과 associated non-parametric learning 알고리즘은 충분한 데이터가 있을때 잘 작동합니다. 이 데이터들은 학습해야할 underlying function의 peak, valleys를 관찰 할 수 있도록 해야 합니다. 이는 함수가 충분히 smooth하고 몇몇의 차원에 충분히 퍼져있다면 일반적으로 사실입니다. 고차원에서는 매우 smooth function은 매우 천천히 변하지만 각각의 차원에 모든 방향에 대해서 변할 수 있습니다. 만약 함수가 다른 region에서 다르게 행동한다면 train sample로는 설명하기 힘들게 됩니다. 만약 함수가 매우 복잡하다면 (이 의미는 example의 갯수보다 더 많은 region을 분별하고 싶다면)  일반화를 잘 하기 위한 다른 방법이 있을까요?\n",
    "\n",
    "복잡한 함수를 효율적으로 representation하는 것이 가능할까?, 새로운 인풋에 대해 추정된 함수가 일반화 하는 것이 가능할까에 대한 답은 yes입니다. underlying data generating distribution에 대한 몇가지 가정을 추가함으로써 새로운 region과의 관계를 도입하여 매우 많은 region ex) O(2^k) 들도 O(k) example에 의해 정의될 수 있다는 것이 중요합니다. 이러한 방법을 통해 우리는 non-locally generalize 할 수 있습니다. 많은 다양한 딥러닝 알고리즘은 이러한 일반화를 하기 위해 implicit or explicit 가정들을 제공합니다.\n",
    "\n",
    "머신러닝을 더 강력하게 만들어주는 다른 접근은 task-specific assumption입니다. 예를들어 target function이 주기적이라는 가정을 하면 위에서 설명한 체스판 문제를 매우 쉽게 풀 수 있습니다. 이렇게 강한 가정이 아니더라도 task-specific assumption을 뉴럴넷에 넣음으로써 이들은 일반화를 더 잘할 수 있게 됩니다. AI task들은 간단하게 나타내기에 너무 복잡한 구조를 가지고 있으며 그래서 learning 알고리즘이 좀 더 general-purpose assumption을 가지도록 해야 합니다. <b>딥러닝의 중심 아이디어는 데이터가 composition of feature 에 의해 생성된다는 것이며 계층적 구조를 뛰고 있다는 것입니다. </b> 이와 비슷한 일반적인 가정들은 딥러닝 알고리즘을 발전 시킬 수 잇습니다. 이러한 가정들은 example의 갯수와 구별 가능한 region 사이의 지수적 증가를 하도록 합니다. 이러한 exponentail gain은 추후에 더 설명 합니다. <b> 딥하며, distributed representation한 가정을 가지는 딥러닝은 exponential advantage를 갖게되며 이는 차원의 저주에서 제시된 exponential challenge를 해결합니다.</b>\n",
    "\n",
    "\n",
    "### 정리\n",
    "    1. local constancy, smoothness, local generalization은 다 비슷한 의미이다. ex) L2-norm, 하여튼 local constancy 는 reasonable한 prior이다.\n",
    "    2. smoothness 만으로 m개의 train example로 O(m) region 밖에 구별못함... 즉 차원의 저주는 치명적이며 smoothness 만으로 차원의 저주를 해결하지 못한다.\n",
    "    4. 하지만 새로운 prior 혹은 가정을 추가함으로써 exponenential region gain이 가능\n",
    "    5. 딥러닝의 composition of feature, distributed representation의 priror가 exponential region gain을 가능하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11.3 Manifold Learning\n",
    "\n",
    "머신러닝에서의 중요한 아이디어중 하나가 바로 manifold 입니다. \n",
    "\n",
    "manifold는 연결된 region이며 수학적으로 이는 이웃한 point들과 연결된 point의 집합입니다. 어떤 point가 주어진다면 manifold는 locally 하게는 유클리디언 공간으로 나타납니다. 우리는 일상생활에서 실제 세계인 3d space에서의 2d plane surface를 항상 경험하고 있습니다. \n",
    "\n",
    "각 점에대한 이웃한 점의 정의는 한 매니폴드를 근처 위치로 이동할 수 있는 변환들을 정의하게 됩니다. 예를들어 surface를 매니폴드로 생각하면 가능한 변환들은 north, south, east, west가 됩니다.\n",
    "\n",
    "매니폴드에 대한 명확한 수학적 의미가 있음에도 머신러닝에서는 더 느슨한 정의를 사용합니다. 이를 통해 point의 connected set을 설계하는데 이 set을 적은 자유도, 차원, embedded high dimensional space를 통해 근사할 수 있도록 하기 위해서입니다. 각 차원은 변형(variation?? 데이터의 변형들???)의 local direction에 대응하게 됩니다. 5.11 그림을 보면 train example이 2d space 에서 embedding된 1d 매니폴드 근처에 놓여져 있는 것을 볼 수 있습니다. 머신러닝에서는 매니폴드의 차원이 어떤 한포인트와 다른 포인트와 다를 수 있도록 합니다. 이는 매니폴드가 자신과 교집합이 있을 떄 발생합니다. 예를들어  8 이라는 숫자는 2d space상에서 embedding된 1d 매니폴드 이지만 센터의 교점은 2차원의 매니폴드를 가집니다. \n",
    "\n",
    "머신러닝 알고리즘이 R^n 에서의 모든 가능한 변형?(변환? 모든 가능한 변환들을 고려해야 한다면?)들을 배울 것이라고 기대한다면 이는 매우 절망적입니다. <b>Manifold learning</b> 은 R^n 공간의 대부분이 불필요하다고 가정함으로써 이러한 것을 해결합니다. 또한 관심을 가지고 있는 input은 point에 대한 부분 집합을 포함하는 매니폴드의 집합을 따라 발생하며 학습된 함수의 출력에서의 관심있는 변환?변형?? 들은 매니폴드에 놓여있는 방향에 따라서만 발생하며 관심가지는 변형들은 한 매니폴드에서 다른 매니폴드로 이동할 때만 일어난다고 가정합니다.\n",
    "\n",
    "매니폴드 학습은 unsupervised learning과 continous-value를 학습하기 위해 도입되었고 이러한 probability concentration(확률적으로 공간에서 특정한 곳에만 모여있다는 뜻인가?) 아이디어는 discreate data, supervised learning 으로 확장되엇습니다. 주요한 가정은 pmf 가 매우 집중되어져 있다는 것입니다.\n",
    "\n",
    "데이터가 낮은 차원의 매니폴드에 집중되어져 있다는 것은 항상 옳거나 유용한 것은 아닙니다. 하지만 AI task, 이미지처리, 음성, 텍스트 에서는 매니폴드 가정이 적어도 근사적으로는 옳습니다. 이러한 가정에 대한 증거는 다음과 같습니다.\n",
    "\n",
    "매니폴드 가설에 대한 첫번째 관찰은 실제로 나타나는 이미지, 텍스트, 음성의 확률분포는 매우 집중되어져 있다는 것입니다. uniform noise는 절대로 이러한 구조화된 이미지, 텍스트, 음성과 닮지 않았습니다. 피규어 5.12는 uniform하게 샘플링된 점들이  신호가 없을 때 나타나는 아날로그 TV 의 이미지처럼 보이는 것을 보여줍니다. 비슷하게 글자를 유니폼하게 샘플링하여 문서를 만든다면 의미가 있는 문서를 만들 확률이 얼마일까요? 이는 Almost zero입니다. 랜덤하게 샘플링되어져 만들어진 문서들은 자연 언어에 대응되지 않기 때문에 natural language sequence의 분포는 전체 공간의 매우 일부분만을 차지하고 있을 것입니다.\n",
    "\n",
    "물론 집중된 확률분포가 데이터가 몇개의 그럴듯한 매니폴드에 놓여져 있다는 것을 의미하는 것은 아닙니다. 또한 우리가 만나게 되는 example들이 서로서로 연결되어져 있음을 확증해야 합니다. 각 예제들은 매니폴드를 옮겨가는 변환을 적용함으로써 얻을수 있는 다른 비슷한 example들로 둘러쌓여져 있는지 알아야 합니다.\n",
    "\n",
    "매니폴드 가설에 대한 두번째 주장은 수식적은 아닐지라도 인접한 example과 변환들에 대한 지식을 알고 잇다는 것입니다. 이미지의 경우 몇몇 가능한 변환들을 상상할 수 잇으며 이는 image space에서의 매니폴드를 추적 할 수 있도록 합니다. 우리는 밝기를 변환가능하며 이미지 안의 오브젝트를 회전 혹은 translation 할 수 있습니다. 객체의 surface color를 변환가능 하며 이들은 모두 점진적으로 변환할 수 있습니다. 대부분의 어플리케이션에서는 여러개의 매니폴드가 있을 가능성이 높습니다. 예를들어 사람 얼굴에 대한 매니폴드는 고양이 얼굴에 대한 매니폴드와 연결되어져있지 않을 것입니다.\n",
    "\n",
    "데이터가 낮은 차원 매니폴드에 놓여져 있을때 데이터를 이 매니폴드 안에서의 coordinate로 표현하는 것은 머신러닝이 하고자 하는 일이 됩니다. 일상생활에서 길은 일종의 3d space에서의 1d 매니폴드로 생각 할 수 있습니다. 우리는 이 1d road에 붙어있는 주소를 통해 방향을 알려 줄 수 있습니다. 이러한 매니폴드 coordinate를 추출하는 것은 매우 어렵습니다. 하지만 많은 기계학습 알고리즘을 개선시킬 수 잇는 가능성을 가지고 있습니다. 이러한 일반적인 원리는 다양한 곳에서 적용됩니다. 피규어 5.13은 얼굴로 구성된 데이터셋의 매니폴드 구조를 보여줍니다. 이 책의 끝에서는 이러한 매니폴드 구조를 배우는 방법론을 소개할 것입니다. 피규어 20.6에서 이러한 것을 성공한 머신러닝 알고리즘을 볼 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
